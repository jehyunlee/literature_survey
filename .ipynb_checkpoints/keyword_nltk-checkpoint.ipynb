{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, re, nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "Lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus = pd.read_csv(\"scopus.csv\")\n",
    "keyword_org_name = \"keywords.txt\"\n",
    "keyword_abb_name = \"keywords_abb.json\"\n",
    "keyword_dash_name = \"keywords_dash.json\"\n",
    "keyword_dict_name = \"keywords_dict.json\"\n",
    "keyword_single_name = \"keywords_single.txt\"\n",
    "keyword_plural_name = \"keywords_plural.json\"\n",
    "unicode_name = \"unicode_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unicode dictionary\n",
    "with open('unicode_dict.json') as j:\n",
    "    unicode_dict = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "line = ''\n",
    "\n",
    "with open(\"BIPV_ML_all.txt\") as f:\n",
    "    while line != \"EF\":\n",
    "        line = f.readline()\n",
    "        if line[:3] == \"DE \":\n",
    "            keywords_new = line[3:].rstrip('\\n').split(\";\")\n",
    "            for keyword_new in keywords_new:\n",
    "                keywords += [keyword_new.rstrip(' ').lstrip(' ')]\n",
    "\n",
    "keywords = sorted(keywords)\n",
    "with open(keyword_org_name, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    for keyword in keywords:\n",
    "        f.write(f\"{keyword}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreive keywords\n",
    "keywords_raw_ = np.genfromtxt(\"keywords.txt\", dtype=\"str\", delimiter=\"\\n\", encoding='utf-8-sig') #utf-8-sig for \\ufeff removal\n",
    "\n",
    "# get unique ones\n",
    "keywords_raw_ = np.unique(keywords_raw_)\n",
    "\n",
    "# abbriviations detection (key candidates)\n",
    "keywords_abb = {}\n",
    "keywords_abb_key_cand = []\n",
    "for keyword_raw_ in keywords_raw_:\n",
    "    kwr = keyword_raw_.split()\n",
    "    for kw in kwr:\n",
    "        kw = kw.lstrip(\"(\").rstrip(\")\")\n",
    "        if (kw == kw.upper()) \\\n",
    "           and (kw.lstrip(\"(\").rstrip(\")\") not in keywords_abb_key_cand) \\\n",
    "           and (ord(kw[0]) >= ord('A') and ord(kw[0]) <= ord('Z')) \\\n",
    "           and (len(kw) > 1):\n",
    "            keywords_abb_key_cand.append(kw.lstrip(\"(\").rstrip(\")\").rstrip(\":\").rstrip(\",\"))\n",
    "\n",
    "# convert to lower cases\n",
    "keywords_raw = [kw.lower() for kw in keywords_raw_]\n",
    "\n",
    "# duplicate for values\n",
    "keywords_value = deepcopy(keywords_raw)\n",
    "\n",
    "### keywords cleaning\n",
    "keywords_dash = [] # additional dictionary, for words containing '-'\n",
    "\n",
    "# remove staring characters\n",
    "keywords_value = [kw.lstrip('-') for kw in keywords_value]\n",
    "keywords_value = [kw.rstrip('-') for kw in keywords_value]\n",
    "keywords_value = [kw.lstrip(':') for kw in keywords_value]\n",
    "keywords_value = [kw.rstrip(':') for kw in keywords_value]\n",
    "\n",
    "# remove brakets \"()\"\n",
    "for kc in keywords_abb_key_cand:\n",
    "    kc_ = kc.lower()\n",
    "    for kw in keywords_value:\n",
    "        if kc_ in kw.replace('(', \"\").replace(')', \"\").split():\n",
    "            kc_value = re.sub(r'\\([^)]*\\)', \"\", kw).rstrip(' ').lstrip(' ')\n",
    "            if (kc_ not in kc_value) and \\\n",
    "               (kc_value[-1] != \")\") and \\\n",
    "               (len(kc_value.split()) > 1) and \\\n",
    "               ((kc not in list(keywords_abb.keys())) or (kc in list(keywords_abb.keys()) and len(kc_value) < len(keywords_abb[kc]) and len(kc_value.split()) > 1)):\n",
    "                kc_value = kc_value.replace(\"  \", \" \")\n",
    "                kc_value = ' '.join(kc_value.split(' ')[:-1] + [Lem.lemmatize(kc_value.split(' ')[-1])])\n",
    "                keywords_abb.update({kc:kc_value})\n",
    "\n",
    "keywords_value = [re.sub(r'\\([^)]*\\)', \"\", kw).rstrip(' ').lstrip(' ').lstrip(')').lstrip('(') for kw in keywords_value]\n",
    "\n",
    "# remove unicodes â€“\n",
    "unicode_keys = list(unicode_dict.keys())\n",
    "for ukey in unicode_keys:\n",
    "        keywords_value = [kw.replace(ukey, unicode_dict[ukey]) for kw in keywords_value]\n",
    "\n",
    "# remove mathematics\n",
    "keywords_value = [kw.replace(\"\\\\infty\", \"infinity\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"\\\\mathrm{\", \"\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"{\", \"\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"}\", \"\") for kw in keywords_value]\n",
    "\n",
    "# remove '\"'\n",
    "keywords_value = [kw.replace('\"', \"\") for kw in keywords_value]\n",
    "\n",
    "# reduce needless blanks.\n",
    "keywords_value = [re.sub(\"\\s+\", \" \", kw) for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\" -\", \"-\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"- \", \"-\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\" //\", \"//\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"// \", \"//\") for kw in keywords_value]\n",
    "\n",
    "# create single-word keyword\n",
    "keywords_single = []\n",
    "for kw in keywords_value:\n",
    "    if len(kw.split()) == 1 and len(kw) <= 4:\n",
    "        keywords_single.append(kw)\n",
    "\n",
    "# Convert plural to singular\n",
    "Lem = WordNetLemmatizer()\n",
    "keywords_plural = {}\n",
    "keywords_value_ = []\n",
    "for i, kw in enumerate(keywords_value):\n",
    "    if (kw not in keywords_single) and (len(kw.split(' ')) > 1):\n",
    "        kw_ = ' '.join(kw.split(' ')[:-1] + [Lem.lemmatize(kw.split(' ')[-1])])\n",
    "        keywords_value_.append(kw_)\n",
    "    else:\n",
    "        keywords_value_.append(kw)\n",
    "        \n",
    "    kw_ = kw.split(' ')\n",
    "    for kw__ in kw_:\n",
    "        if kw__ not in keywords_single and Lem.lemmatize(kw__) != kw__:\n",
    "            keywords_plural.update({kw__: Lem.lemmatize(kw__)})\n",
    "\n",
    "keywords_value = deepcopy(keywords_value_)\n",
    "        \n",
    "    \n",
    "# keywords_value = [' '.join(kw.split(' ')[:-1] + [Lem.lemmatize(kw.split(' ')[-1])] if len(kw.split(' ')) > 1 and not in keywords_single else kw for kw in keywords_value]\n",
    "\n",
    "keywords_value = [kw.lstrip(' ').rstrip(' ') for kw in keywords_value]\n",
    "    \n",
    "# create dash dictionary\n",
    "for kw in keywords_value:\n",
    "    kw_ = kw.split(\" \")\n",
    "    for kw__ in kw_:\n",
    "        if ('-' in kw__) or ('//' in kw__):\n",
    "            keywords_dash.append(kw__)\n",
    "    \n",
    "keywords_dash = np.unique(keywords_dash)\n",
    "\n",
    "# create dictionary\n",
    "keywords_dict = dict(zip(keywords_raw, keywords_value))\n",
    "with open(keyword_dict_name, \"w\") as j:\n",
    "    json.dump(keywords_dict, j, ensure_ascii=False, indent=2)\n",
    "    \n",
    "# create plural-singular dictionary\n",
    "plural_sorted = dict(sorted(keywords_plural.items()))\n",
    "with open(keyword_plural_name, \"w\") as j:\n",
    "    json.dump(plural_sorted, j, ensure_ascii=False, indent=2)\n",
    "\n",
    "# create abbreviation dictionary\n",
    "abb_sorted = dict(sorted(keywords_abb.items()))\n",
    "with open(keyword_abb_name, \"w\") as j:\n",
    "    json.dump(abb_sorted, j, ensure_ascii=False, indent=2)\n",
    "\n",
    "# create \"dash\" keywords dictionary - manual refinement required\n",
    "keywords_dash_dict = dict(zip(keywords_dash, keywords_dash))\n",
    "with open(keyword_dash_name, \"w\") as j:\n",
    "    json.dump(keywords_dash_dict, j, ensure_ascii=False, indent=2)\n",
    "\n",
    "# create \"dash\" keywords list\n",
    "with open(keyword_single_name, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    for keyword in keywords_single:\n",
    "        f.write(f\"{keyword}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual keywords-abb refinement\n",
    "* incorrect names, typo errors\n",
    "* unifying same words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual keyworkds-dash refinement\n",
    "* incorrect names, typo errors\n",
    "* unifying same words (ex. photo-voltaic and photovoltaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keywords_abb_refine.json\", \"r\") as j:\n",
    "    keywords_abb_refine = json.load(j)\n",
    "\n",
    "with open(\"keywords_dash_refine.json\", \"r\") as j:\n",
    "    keywords_dash_refine = json.load(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb_refine_keys = list(keywords_abb_refine.keys())\n",
    "abb_refine_values = list(keywords_abb_refine.values())\n",
    "dash_refine_keys = list(keywords_dash_refine.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-multigeneration\n",
      "micro-pv\n",
      "micro-satellite\n",
      "micro-system\n",
      "micro-turbine\n",
      "mid-frequency\n",
      "mid-long\n",
      "mid-point\n",
      "mid-to-long\n",
      "mil-217\n",
      "mil-hdbk-217f\n",
      "min-max\n",
      "mini-grid\n",
      "mini-grid\n",
      "mini-module\n",
      "mission-based\n",
      "mixed-integer\n",
      "mixed-use\n",
      "mode-based\n",
      "model-based\n"
     ]
    }
   ],
   "source": [
    "for dkey in dash_refine_keys[630:650]:\n",
    "    print(keywords_dash_refine[dkey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pv' == \"PV\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lssvm'] ['least square support vector machine'] ['']\n",
      "['long short-term memory', 'convolutional neural network'] [] []\n",
      "['long short-term memory'] [] []\n",
      "['luo-converter'] [] []\n",
      "['m-flc'] ['fuzzy logic control'] ['m']\n",
      "['m-matrix'] [] []\n",
      "['machine-learning'] [] []\n",
      "['machine-learning'] [] []\n",
      "['mamdani-based'] [] []\n",
      "['mass-loss'] [] []\n",
      "['master-slave'] [] []\n",
      "['matlab'] [] []\n",
      "['matlab-simulink'] [] []\n",
      "['maximum-power-point'] [] []\n",
      "['maximum-power-point-tracking'] [] []\n",
      "['maximum-power-point-tracking'] [] []\n",
      "['measurement-based'] [] []\n",
      "['med-tvc'] [] []\n",
      "['medium-and'] [] []\n",
      "['medium-term'] [] []\n",
      "['medium-voltage'] [] []\n",
      "['mega-solar'] [] []\n"
     ]
    }
   ],
   "source": [
    "for dkey in dash_refine_keys[588:610]:\n",
    "    dvalues = keywords_dash_refine[dkey].split(\"; \")\n",
    "#     print(dvalues)\n",
    "    dvalues_abb = []\n",
    "    dvalues_rems = []\n",
    "    dvalues_refine = []\n",
    "    for dvalue in dvalues:\n",
    "        dvalue_rem = deepcopy(dvalue)\n",
    "        for akey in abb_refine_keys:\n",
    "            if dvalue == akey.lower():\n",
    "                dvalues.remove(dvalue)\n",
    "                dvalues.append(keywords_abb_refine[akey])\n",
    "                \n",
    "                \n",
    "            [dvalues_abb.append(keywords_abb_refine[d.upper()]) for d in dvalue.split(\"-\") if d == akey.lower()]\n",
    "            [dvalues_rems.append(dvalue_rem.replace(d, \"\").rstrip(\"-\").lstrip(\"-\")) for d in dvalue.split(\"-\") if d == akey.lower()]\n",
    "#             dvalues_abb += [[keywords_abb_refine[d.upper()], dvalue_rem.replace(d, \"\").rstrip(\"-\").lstrip(\"-\")] for d in dvalue.split(\"-\") if d == akey.lower()]\n",
    "            \n",
    "#             if dvalue == \"micro-pv\":\n",
    "#                 print(dvalues_)\n",
    "#         dvalue__ = [d for d in dvalues_]\n",
    "    print(dvalues, dvalues_abb, dvalues_rems)\n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find words matching with \"keywords_dash\" with same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_value_sort = np.unique(keywords_value, return_counts=True)\n",
    "\n",
    "df_keywords_value = pd.DataFrame({\"keyword\": keywords_value_sort[0],\n",
    "                                         \"counts\": keywords_value_sort[1],\n",
    "                                        }).sort_values(\"keyword\")\n",
    "df_keywords_value.to_csv(\"keywords_value.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prostate-specific antigen',\n",
       " '% free psa',\n",
       " 'photo voltaic',\n",
       " 'voltage power',\n",
       " 'dynamic carbon intensity',\n",
       " 'direct current',\n",
       " 'geographic information system',\n",
       " 'voltage regulator runaway',\n",
       " 'absorption chiller',\n",
       " 'aerosol index']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(keywords_abb.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modified particle swarm optimisation']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([val for val in list(keywords_abb.values()) if (\"optimis\" in val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "7 ['photo-voltaic']\n",
      "8 ['1-d']\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 ['coupled-inductor']\n",
      "13 []\n",
      "14 ['look-up']\n",
      "15 ['2-dof-pi-fopdn']\n",
      "16 []\n",
      "17 ['3-d']\n",
      "18 ['20-sim']\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "22 ['2-d']\n",
      "23 ['2-d']\n",
      "24 ['2-d']\n",
      "25 ['2-d']\n",
      "26 ['2-d']\n",
      "27 []\n",
      "28 []\n",
      "29 []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>counts</th>\n",
       "      <th>relwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% free psa</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-d modeling</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-mhz frequency</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-year prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100% reliability</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100% renewable energy</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 min and 24 h ahead power prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500-v photovoltaic</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1d dymola</td>\n",
       "      <td>1</td>\n",
       "      <td>[1-d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1d5p model</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 deg.c target</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 to 4 level converter</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 winding coupled inductor</td>\n",
       "      <td>1</td>\n",
       "      <td>[coupled-inductor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2-d steady-state</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2-dimensional lookup table</td>\n",
       "      <td>2</td>\n",
       "      <td>[look-up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2-dof-pi-fopdn</td>\n",
       "      <td>1</td>\n",
       "      <td>[2-dof-pi-fopdn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2-stage forecasting</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.5d and 3d approach</td>\n",
       "      <td>1</td>\n",
       "      <td>[3-d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20-sim</td>\n",
       "      <td>1</td>\n",
       "      <td>[20-sim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-w/1-t co2 society vision</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   keyword  counts            relwords\n",
       "0                               % free psa       1                  []\n",
       "1                             1-d modeling       1                  []\n",
       "2                          1-mhz frequency       1                  []\n",
       "3                       10-year prediction       1                  []\n",
       "4                         100% reliability       1                  []\n",
       "5                    100% renewable energy       1                  []\n",
       "6   15 min and 24 h ahead power prediction       1                  []\n",
       "7                      1500-v photovoltaic       1     [photo-voltaic]\n",
       "8                                1d dymola       1               [1-d]\n",
       "9                               1d5p model       1                  []\n",
       "10                          2 deg.c target       1                  []\n",
       "11                  2 to 4 level converter       1                  []\n",
       "12              2 winding coupled inductor       1  [coupled-inductor]\n",
       "13                        2-d steady-state       1                  []\n",
       "14              2-dimensional lookup table       2           [look-up]\n",
       "15                          2-dof-pi-fopdn       1    [2-dof-pi-fopdn]\n",
       "16                     2-stage forecasting       1                  []\n",
       "17                    2.5d and 3d approach       1               [3-d]\n",
       "18                                  20-sim       1            [20-sim]\n",
       "19           2000-w/1-t co2 society vision       1                  []"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_value = pd.read_csv(\"keywords_value.csv\")\n",
    "df_keywords_value[\"relwords\"] = [[] for i in range(len(df_keywords_value))]\n",
    "\n",
    "for i in range(30):\n",
    "    words0 = df_keywords_value[\"keyword\"].iloc[i]\n",
    "    words1 = words0.split(\" \")\n",
    "    words2 = words0.split(\"-\")\n",
    "#     df_keywords_value.loc[i, \"relwords\"] = []\n",
    "    \n",
    "    for kws in keywords_dash:\n",
    "        kws_ = kws.replace(\"-\", \"\")\n",
    "        if kws_ in words1:\n",
    "            df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "#             print(\"try0\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "\n",
    "        kws_ = kws.split('-')\n",
    "        try:\n",
    "            tmp = [words1.index(kw_) for kw_ in kws_]\n",
    "            if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "#                 print(\"try1\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                tmp = [words2.index(kw_) for kw_ in kws_]\n",
    "                if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                    df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "#                     print(\"try2\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    print(i, df_keywords_value[\"relwords\"].iloc[i])\n",
    "\n",
    "df_keywords_value.head(20)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>counts</th>\n",
       "      <th>relwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% free psa</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-d modeling</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-mhz frequency</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-year prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100% reliability</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100% renewable energy</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 min and 24 h ahead power prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500-v photovoltaic</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1d dymola</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1d5p model</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 deg.c target</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 to 4 level converter</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 winding coupled inductor</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2-d steady-state</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2-dimensional lookup table</td>\n",
       "      <td>2</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2-dof-pi-fopdn</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2-stage forecasting</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.5d and 3d approach</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20-sim</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-w/1-t co2 society vision</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   keyword  counts  \\\n",
       "0                               % free psa       1   \n",
       "1                             1-d modeling       1   \n",
       "2                          1-mhz frequency       1   \n",
       "3                       10-year prediction       1   \n",
       "4                         100% reliability       1   \n",
       "5                    100% renewable energy       1   \n",
       "6   15 min and 24 h ahead power prediction       1   \n",
       "7                      1500-v photovoltaic       1   \n",
       "8                                1d dymola       1   \n",
       "9                               1d5p model       1   \n",
       "10                          2 deg.c target       1   \n",
       "11                  2 to 4 level converter       1   \n",
       "12              2 winding coupled inductor       1   \n",
       "13                        2-d steady-state       1   \n",
       "14              2-dimensional lookup table       2   \n",
       "15                          2-dof-pi-fopdn       1   \n",
       "16                     2-stage forecasting       1   \n",
       "17                    2.5d and 3d approach       1   \n",
       "18                                  20-sim       1   \n",
       "19           2000-w/1-t co2 society vision       1   \n",
       "\n",
       "                                             relwords  \n",
       "0   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "1   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "2   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "3   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "4   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "5   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "6   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "7   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "8   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "9   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "10  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "11  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "12  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "13  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "14  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "15  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "16  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "17  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "18  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "19  [photo-voltaic, 1-d, coupled-inductor, look-up...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_value.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try0 ['36-cell pv module'] 6 p-v [1, 1]\n",
      "try1 ['36-cell pv module'] 6 pv-module [1, 2]\n",
      "try0 ['3d'] 7 3-d [1, 2]\n",
      "try0 ['3d building model'] 8 3-d [1, 2]\n",
      "try0 ['3d city model'] 9 3-d [1, 2]\n",
      "try0 ['3d density model'] 10 3-d [1, 2]\n",
      "try0 ['3d experiment'] 11 3-d [1, 2]\n",
      "try0 ['3d finite element'] 12 3-d [1, 2]\n",
      "try1 ['3d finite element'] 12 finite-element [1, 2]\n",
      "try0 ['3d finite-volume modeling'] 13 3-d [1, 2]\n",
      "try0 ['3d gi'] 14 3-d [1, 2]\n",
      "try0 ['3d model'] 15 3-d [1, 2]\n",
      "try0 ['3d numerical model'] 16 3-d [1, 2]\n",
      "try0 ['3d radiative transfer'] 17 3-d [1, 2]\n",
      "try0 ['3d solar cell modeling'] 18 3-d [1, 2]\n",
      "try0 ['3d solar city'] 19 3-d [1, 2]\n",
      "try0 ['3d solar radiation model'] 20 3-d [1, 2]\n",
      "try0 ['3d urban model'] 21 3-d [1, 2]\n",
      "try2 ['3d-tlm'] 22 3d-tlm [0, 1]\n",
      "try2 ['3l-anpc'] 23 3l-anpc [0, 1]\n",
      "try2 ['4-terminal'] 24 4-terminal [0, 1]\n",
      "try1 ['5-level single phase converter'] 27 single-phase [1, 2]\n"
     ]
    }
   ],
   "source": [
    "df_keywords_value = pd.read_csv(\"keywords_value.csv\")\n",
    "\n",
    "df_tmp = df_keywords_value.iloc[30:60].reset_index(drop=True)\n",
    "df_tmp[\"relwords\"] = np.nan\n",
    "\n",
    "for i in range(30):\n",
    "    words0 = df_tmp[\"keyword\"].iloc[i]\n",
    "    words1 = words0.split(\" \")\n",
    "    words2 = words0.split(\"-\")\n",
    "    \n",
    "    for kws in keywords_dash:\n",
    "        kws_ = kws.replace(\"-\", \"\")\n",
    "        if kws_ in words1:\n",
    "            print(\"try0\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "\n",
    "        kws_ = kws.split('-')\n",
    "        try:\n",
    "            tmp = [words1.index(kw_) for kw_ in kws_]\n",
    "            if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                print(\"try1\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                tmp = [words2.index(kw_) for kw_ in kws_]\n",
    "                if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                    print(\"try2\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_value_single = []\n",
    "p = re.compile(\"[a-zA-Z]\")\n",
    "\n",
    "abbkeys_ = list(keywords_abb.keys())\n",
    "abbkeys = [key.lower() for key in abbkeys]\n",
    "pluralkeys = list(keywords_plural.keys())\n",
    "\n",
    "for keyword_value in keywords_value:\n",
    "    kws = keyword_value.replace(',', \"\").split(' ')\n",
    "    for kw in kws:\n",
    "        if p.match(kw) and (kw not in abbkeys) and (kw not in keywords_dash):\n",
    "            keywords_value_single.append(kw)\n",
    "\n",
    "keywords_value_single = np.unique(keywords_value_single, return_counts=True)\n",
    "\n",
    "df_keywords_value_single = pd.DataFrame({\"keyword\": keywords_value_single[0],\n",
    "                                         \"counts\": keywords_value_single[1],\n",
    "                                         \"relwords\": [keywords_plural[kw] if kw in pluralkeys else kw for kw in keywords_value_single[0]]\n",
    "                                        })\n",
    "df_keywords_value_single[df_keywords_value_single[\"counts\"]>5].to_csv(\"keywords_relwords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* manual operation on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_noun_dict = {}\n",
    "keywords_noun_ = list(keywords_abb.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
