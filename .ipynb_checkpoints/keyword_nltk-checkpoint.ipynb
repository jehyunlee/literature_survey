{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, re, nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "Lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus = pd.read_csv(\"scopus.csv\")\n",
    "keyword_org_name = \"keywords.txt\"\n",
    "keyword_abb_name = \"keywords_abb.json\"\n",
    "keyword_dash_name = \"keywords_dash.json\"\n",
    "keyword_dict_name = \"keywords_dict.json\"\n",
    "keyword_single_name = \"keywords_single.txt\"\n",
    "keyword_plural_name = \"keywords_plural.json\"\n",
    "unicode_name = \"unicode_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unicode dictionary\n",
    "with open('unicode_dict.json') as j:\n",
    "    unicode_dict = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "line = ''\n",
    "\n",
    "with open(\"BIPV_ML_all.txt\") as f:\n",
    "    while line != \"EF\":\n",
    "        line = f.readline()\n",
    "        if line[:3] == \"DE \":\n",
    "            keywords_new = line[3:].rstrip('\\n').split(\";\")\n",
    "            for keyword_new in keywords_new:\n",
    "                keywords += [keyword_new.rstrip(' ').lstrip(' ')]\n",
    "\n",
    "keywords = sorted(keywords)\n",
    "with open(keyword_org_name, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    for keyword in keywords:\n",
    "        f.write(f\"{keyword}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerosols\n",
      "aggregators\n",
      "agrivoltaics\n",
      "algorithms\n",
      "barriers\n",
      "bifurcations\n",
      "buildings\n",
      "characteristics\n",
      "choppers\n",
      "clouds\n",
      "consumers\n",
      "controllers\n",
      "converters\n",
      "correlations\n",
      "costs\n",
      "delays\n",
      "dielectrics\n",
      "diodes\n",
      "dislocations\n",
      "dynamics\n",
      "economics\n",
      "eigenvalues\n",
      "electrolyzers\n",
      "emissions\n",
      "ensembles\n",
      "experiments\n",
      "failures\n",
      "faults\n",
      "feed-in-tariffs\n",
      "forecasts\n",
      "greenhouses\n",
      "harmonics\n",
      "heterojunctions\n",
      "households\n",
      "hurricanes\n",
      "ibscs\n",
      "igbts\n",
      "imports\n",
      "inverters\n",
      "irradiances\n",
      "measurements\n",
      "metaheuristics\n",
      "micro-grids\n",
      "microgrids\n",
      "microinverters\n",
      "microturbines\n",
      "mini-grids\n",
      "modes\n",
      "models\n",
      "modules\n",
      "multi-junctions\n",
      "nano-grids\n",
      "nanofluids\n",
      "nanowires\n",
      "optoelectronics\n",
      "performances\n",
      "perovskites\n",
      "photodetectors\n",
      "photodiodes\n",
      "photovoltaics\n",
      "prosumers\n",
      "relays\n",
      "renewables\n",
      "resonances\n",
      "scenarios\n",
      "semiconductors\n",
      "sensors\n",
      "simulations\n",
      "simulators\n",
      "supercapacitors\n",
      "systems\n",
      "techno-economics\n",
      "technoeconomics\n",
      "thermodynamics\n",
      "thermophotovoltaics\n",
      "transients\n",
      "trends\n",
      "voltages\n",
      "waves\n",
      "wavelets\n"
     ]
    }
   ],
   "source": [
    "# retreive keywords\n",
    "keywords_raw_ = np.genfromtxt(\"keywords.txt\", dtype=\"str\", delimiter=\"\\n\", encoding='utf-8-sig') #utf-8-sig for \\ufeff removal\n",
    "\n",
    "# get unique ones\n",
    "keywords_raw = np.unique(keywords_raw_)\n",
    "\n",
    "# abbriviations detection (key candidates)\n",
    "keywords_abb = {}\n",
    "keywords_abb_key_cand = []\n",
    "for keyword_raw_ in keywords_raw_:\n",
    "    kwr = keyword_raw_.split()\n",
    "    for kw in kwr:\n",
    "        kw = kw.lstrip(\"(\").rstrip(\")\")\n",
    "        if (kw == kw.upper()) \\\n",
    "           and (kw.lstrip(\"(\").rstrip(\")\") not in keywords_abb_key_cand) \\\n",
    "           and (ord(kw[0]) >= ord('A') and ord(kw[0]) <= ord('Z')) \\\n",
    "           and (len(kw) > 1):\n",
    "            keywords_abb_key_cand.append(kw.lstrip(\"(\").rstrip(\")\").rstrip(\":\").rstrip(\",\"))\n",
    "\n",
    "# convert to lower cases\n",
    "# keywords_raw = [kw.lower() for kw in keywords_raw_]\n",
    "\n",
    "# duplicate for values, and convert to lower cases\n",
    "keywords_value = deepcopy(keywords_raw)\n",
    "\n",
    "# convert to lower cases\n",
    "keywords_value = [kw.lower() for kw in keywords_value]\n",
    "\n",
    "# remove staring characters\n",
    "keywords_value = [kw.lstrip('-') for kw in keywords_value]\n",
    "keywords_value = [kw.rstrip('-') for kw in keywords_value]\n",
    "keywords_value = [kw.lstrip(':') for kw in keywords_value]\n",
    "keywords_value = [kw.rstrip(':') for kw in keywords_value]\n",
    "\n",
    "# remove brakets \"()\"\n",
    "for kc in keywords_abb_key_cand:\n",
    "    kc_ = kc.lower()\n",
    "    for kw in keywords_value:\n",
    "        if kc_ in kw.replace('(', \"\").replace(')', \"\").split():\n",
    "            kc_value = re.sub(r'\\([^)]*\\)', \"\", kw).rstrip(' ').lstrip(' ')\n",
    "            if (kc_ not in kc_value) and \\\n",
    "               (kc_value[-1] != \")\") and \\\n",
    "               (len(kc_value.split()) > 1) and \\\n",
    "               ((kc not in list(keywords_abb.keys())) or (kc in list(keywords_abb.keys()) and len(kc_value) < len(keywords_abb[kc]) and len(kc_value.split()) > 1)):\n",
    "                kc_value = kc_value.replace(\"  \", \" \")\n",
    "                kc_value = ' '.join(kc_value.split(' ')[:-1] + [Lem.lemmatize(kc_value.split(' ')[-1])])\n",
    "                keywords_abb.update({kc:kc_value})\n",
    "\n",
    "keywords_value = [re.sub(r'\\([^)]*\\)', \"\", kw).rstrip(' ').lstrip(' ').lstrip(')').lstrip('(') for kw in keywords_value]\n",
    "\n",
    "# remove unicodes â€“\n",
    "unicode_keys = list(unicode_dict.keys())\n",
    "for ukey in unicode_keys:\n",
    "        keywords_value = [kw.replace(ukey, unicode_dict[ukey]) for kw in keywords_value]\n",
    "\n",
    "# remove mathematics\n",
    "keywords_value = [kw.replace(\"\\\\infty\", \"infinity\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"\\\\mathrm{\", \"\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"{\", \"\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"}\", \"\") for kw in keywords_value]\n",
    "\n",
    "# remove '\"'\n",
    "keywords_value = [kw.replace('\"', \"\") for kw in keywords_value]\n",
    "\n",
    "# reduce needless blanks.\n",
    "keywords_value = [re.sub(\"\\s+\", \" \", kw) for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\" -\", \"-\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"- \", \"-\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\" //\", \"//\") for kw in keywords_value]\n",
    "keywords_value = [kw.replace(\"// \", \"//\") for kw in keywords_value]\n",
    "\n",
    "# create single-word keyword\n",
    "keywords_single = [k for k in list(keywords_abb.keys())]\n",
    "for kws in keywords_value:\n",
    "    if len(kws.split(\" \")) == 1 and len(kw) <= 4:\n",
    "        keywords_single.append(kws)\n",
    "    for kw in kws:\n",
    "        if len(kw.split(\"-\")) == 1 and len(kw) <= 4 and len(kw) > 1:\n",
    "            keywords_single.append(kw)\n",
    "\n",
    "keywords_single = list(np.unique(sorted(keywords_single)))\n",
    "\n",
    "keywords_single_ = deepcopy(keywords_single)       \n",
    "for kw in keywords_single_:\n",
    "    if kw+\"s\" in keywords_single and len(kw) >= 4:\n",
    "        print(kw+\"s\")\n",
    "        keywords_single.remove(kw+\"s\")\n",
    "    if kw[-1]+\"ies\" in keywords_single and kw[-1] == \"y\" and len(kw >=4):\n",
    "        print(kw+\"s\")\n",
    "        keywords_single.remove(kw+\"s\")\n",
    "\n",
    "# create abbreviation dictionary\n",
    "abb_sorted = dict(sorted(keywords_abb.items()))\n",
    "with open(keyword_abb_name, \"w\") as j:\n",
    "    json.dump(abb_sorted, j, ensure_ascii=False, indent=2)\n",
    "    \n",
    "# create \"single\" keywords list\n",
    "with open(keyword_single_name, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    for keyword in keywords_single:\n",
    "        f.write(f\"{keyword}\\n\")\n",
    "\n",
    "# create \"value\"\n",
    "keywords_dict = dict(zip(keywords_raw, keywords_value))\n",
    "with open(keyword_dict_name, \"w\") as j:\n",
    "    json.dump(keywords_dict, j, ensure_ascii=False, indent=2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual refine `keywords_single`\n",
    "* plural words not to be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve keywords_value\n",
    "with open(\"keywords_dict.json\", \"r\") as j:\n",
    "    keywords_dict = json.load(j)\n",
    "keywords_value = list(keywords_dict.values())\n",
    "keywords_key = list(keywords_dict.keys())\n",
    "\n",
    "# retreive keywords_single\n",
    "keywords_single = np.genfromtxt(\"keywords_single_refine.txt\", dtype=\"str\", delimiter=\"\\n\", encoding='utf-8-sig') #utf-8-sig for \\ufeff removal\n",
    "keywords_single = [k.lower() for k in keywords_single]\n",
    "\n",
    "# Convert plural to singular\n",
    "Lem = WordNetLemmatizer()\n",
    "keywords_plural = {}\n",
    "keywords_value_ = []\n",
    "for kws in keywords_value:\n",
    "    if (kws not in keywords_single) and (len(kws.split(\" \")) > 1):\n",
    "        kws_0 = kws.split(\" \")\n",
    "        \n",
    "        for kws_1 in kws_0:\n",
    "            kws_2 = kws_1.split(\"-\")\n",
    "            for kw in kws_2:\n",
    "                if (kw not in keywords_single) and (kw != Lem.lemmatize(kw)):\n",
    "                    kws = kws.replace(kw, Lem.lemmatize(kw))\n",
    "                    keywords_plural.update({kw: Lem.lemmatize(kw)})\n",
    "        keywords_value_.append(kws)\n",
    "    else:\n",
    "        keywords_value_.append(kws)\n",
    "\n",
    "keywords_value = deepcopy(keywords_value_)\n",
    "keywords_value = [kw.lstrip(' ').rstrip(' ') for kw in keywords_value]\n",
    "\n",
    "    \n",
    "# create plural-singular dictionary\n",
    "plural_sorted = dict(sorted(keywords_plural.items()))\n",
    "with open(keyword_plural_name, \"w\") as j:\n",
    "    json.dump(plural_sorted, j, ensure_ascii=False, indent=2)\n",
    "    \n",
    "# create \"value\"\n",
    "keywords_dict = dict(zip(keywords_key, keywords_value))\n",
    "with open(keyword_dict_name, \"w\") as j:\n",
    "    json.dump(keywords_dict, j, ensure_ascii=False, indent=2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve keywords_value\n",
    "with open(\"keywords_dict.json\", \"r\") as j:\n",
    "    keywords_dict = json.load(j)\n",
    "keywords_value = list(keywords_dict.values())\n",
    "\n",
    "# create dash dictionary\n",
    "keywords_dash = []\n",
    "for kw in keywords_value:\n",
    "    kw_ = kw.split(\" \")\n",
    "    for kw__ in kw_:\n",
    "        if ('-' in kw__) or ('//' in kw__):\n",
    "            keywords_dash.append(kw__)\n",
    "    \n",
    "keywords_dash = np.unique(keywords_dash)\n",
    "\n",
    "# create \"dash\" keywords dictionary - manual refinement required\n",
    "keywords_dash_dict = dict(zip(keywords_dash, keywords_dash))\n",
    "with open(keyword_dash_name, \"w\") as j:\n",
    "    json.dump(keywords_dash_dict, j, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual keywords-abb refinement\n",
    "* incorrect names, typo errors\n",
    "* unifying same words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual keyworkds-dash refinement\n",
    "* incorrect names, typo errors\n",
    "* unifying same words (ex. photo-voltaic and photovoltaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keywords_plural.json\", \"r\") as j:\n",
    "    keywords_plural = json.load(j)\n",
    "\n",
    "with open(\"keywords_abb_refine.json\", \"r\") as j:\n",
    "    keywords_abb_refine = json.load(j)\n",
    "\n",
    "with open(\"keywords_dash_refine.json\", \"r\") as j:\n",
    "    keywords_dash_refine = json.load(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb_refine_keys = list(keywords_abb_refine.keys())\n",
    "dash_refine_keys = list(keywords_dash_refine.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dash_refine2 = {}\n",
    "\n",
    "plural_keys = list(keywords_plural.keys())\n",
    "\n",
    "for dkey in dash_refine_keys:\n",
    "    dvalues = keywords_dash_refine[dkey].split(\"; \")\n",
    "    \n",
    "    dvalues_abb = []\n",
    "    dvalues_rms = []\n",
    "    for dvalue in dvalues:\n",
    "        dvalue_rem = deepcopy(dvalue)\n",
    "        for akey in abb_refine_keys:\n",
    "            if dvalue == akey.lower():\n",
    "                dvalues.remove(dvalue)\n",
    "                dvalues.append(keywords_abb_refine[akey])\n",
    "            else:\n",
    "                [dvalues_abb.append(keywords_abb_refine[d.upper()]) for d in dvalue.split(\"-\") if d == akey.lower()]\n",
    "                [dvalues_abb.append(keywords_abb_refine[d.upper()]) for d in dvalue.split(\"/\") if d == akey.lower()]\n",
    "\n",
    "    keywords_dash_refine2.update({dkey:dvalues+dvalues_abb})\n",
    "\n",
    "with open(\"keywords_dash_refine2.json\", \"w\") as j:\n",
    "    json.dump(keywords_dash_refine2, j, ensure_ascii=False, indent=2)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual keyworkds_dash2 refinement\n",
    "* incorrect abbs treatement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply keywords-dash on keywords_value\n",
    "* (1) replace keywords_dash_refine.keys() to keywords_dash_refine.values()\n",
    "* (2) if keywords_dash_refine2.key() has more than 2 elements, add them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keywords_dash_refine2.json\", \"r\") as j:\n",
    "    keywords_dash_refine2 = json.load(j)\n",
    "    \n",
    "\n",
    "keywords_value_ = []\n",
    "for kws in keywords_value:\n",
    "    dash_flag = 0\n",
    "    kws_ = []\n",
    "    for dkey in dash_refine_keys:\n",
    "        \n",
    "        if dkey in kws:\n",
    "            kws_ += [kws.replace(dkey, keywords_dash_refine[dkey])]\n",
    "            dash_flag += 1\n",
    "            \n",
    "            if len(keywords_dash_refine2[dkey]) > 1:\n",
    "                [kws_.append(v) for v in keywords_dash_refine2[dkey][1:]]\n",
    "                \n",
    "    if dash_flag == 0:\n",
    "        kws_ = [kws]\n",
    "    \n",
    "    keywords_value_.append(list(np.unique(kws_)))\n",
    "\n",
    "keywords_dict = dict(zip(list(keywords_dict.keys()), keywords_value_))\n",
    "with open(keyword_dict_name, \"w\") as j:\n",
    "    json.dump(keywords_dict, j, ensure_ascii=False, indent=2)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find and extract dash and abbriviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 0 ns, total: 13.6 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "abb_refine_keys = [k.lower() for k in np.unique(list(keywords_abb_refine.keys()))]\n",
    "abb_refine_values = [v.lower() for v in np.unique(list(keywords_abb_refine.values()))]\n",
    "\n",
    "keywords_value_add = []\n",
    "\n",
    "for kw in keywords_value[:1000]:\n",
    "    kw_0 = [kw]\n",
    "    kw_1 = kw.split(\" \")\n",
    "    kw_2 = kw.split(\"-\")\n",
    "    kw_3 = kw.split(\"/\")\n",
    "    \n",
    "    keywords_value_add_ = []\n",
    "    \n",
    "    # \"dash\"\n",
    "    for dash_keys in dash_refine_keys:\n",
    "        if dash_keys in kw_1:\n",
    "            [keywords_value_add_.append(kw) for kw in keywords_dash_refine2[dash_keys]]\n",
    "        \n",
    "        dash_keys_ = dash_keys.replace(\"-\", \"\")\n",
    "        if dash_keys_ in kw_1:\n",
    "            if not (dash_keys_ in abb_refine_keys): # original abbriviation should be kept\n",
    "                [keywords_value_add_.append(kw) for kw in keywords_dash_refine2[dash_keys]]\n",
    "\n",
    "        dash_keys_ = dash_keys.split(\"-\")\n",
    "        if not (dash_keys_ in abb_refine_keys): # original abbriviation should be kept\n",
    "            try:\n",
    "                tmp = [kw_1.index(dash_key_) for dash_key_ in dash_keys_]\n",
    "                if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                    [keywords_value_add_.append(kw) for kw in keywords_dash_refine2[dash_keys]]\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    tmp = [kw_2.index(dash_key_) for dash_key_ in dash_keys_]\n",
    "                    if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                        [keywords_value_add_.append(kw) for kw in keywords_dash_refine2[dash_keys]]\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    \n",
    "    # \"abb\"\n",
    "    for abb_vals in abb_refine_values:\n",
    "        if abb_vals in kw and \\\n",
    "           (abb_vals.replace(\" \", \"-\") not in keywords_value_add) and \\\n",
    "           (abb_vals.replace(\"-\", \" \") not in keywords_value_add):\n",
    "            keywords_value_add_.append(abb_vals)\n",
    "    \n",
    "    for abb_keys in abb_refine_keys:\n",
    "        if abb_keys in (kw_0 + kw_1 + kw_2 + kw_3):\n",
    "            keywords_value_add_.append(keywords_abb_refine[abb_keys.upper()])\n",
    "    \n",
    "    keywords_value_add.append(list(np.unique(keywords_value_add_)))\n",
    "\n",
    "# create \"additional\" keywords dictionary\n",
    "keywords_dict_add = dict(zip(keywords_raw, keywords_value_add))\n",
    "with open(\"keywords_dict_add.json\", \"w\") as j:\n",
    "    json.dump(keywords_dict_add, j, ensure_ascii=False, indent=2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.533333333333333"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13.6*20/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* find words matching with \"keywords_dash\" with same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_value_sort = np.unique(keywords_value, return_counts=True)\n",
    "\n",
    "df_keywords_value = pd.DataFrame({\"keyword\": keywords_value_sort[0],\n",
    "                                         \"counts\": keywords_value_sort[1],\n",
    "                                        }).sort_values(\"keyword\")\n",
    "df_keywords_value.to_csv(\"keywords_value.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prostate-specific antigen',\n",
       " '% free psa',\n",
       " 'photo voltaic',\n",
       " 'voltage power',\n",
       " 'dynamic carbon intensity',\n",
       " 'direct current',\n",
       " 'geographic information system',\n",
       " 'voltage regulator runaway',\n",
       " 'absorption chiller',\n",
       " 'aerosol index']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(keywords_abb.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modified particle swarm optimisation']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([val for val in list(keywords_abb.values()) if (\"optimis\" in val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "try0 ['1500-v photovoltaic'] 7 photo-voltaic [0, 1]\n",
      "7 ['photo-voltaic']\n",
      "try0 ['1d dymola'] 8 1-d [0, 1]\n",
      "8 ['1-d']\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 ['coupled-inductor']\n",
      "13 []\n",
      "try0 ['2-dimensional lookup table'] 14 look-up [2, 3]\n",
      "14 ['look-up']\n",
      "15 ['2-dof-pi-fopdn']\n",
      "16 []\n",
      "try0 ['2.5d and 3d approach'] 17 3-d [0, 1, 2, 3]\n",
      "17 ['3-d']\n",
      "18 ['20-sim']\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "try0 ['2d'] 22 2-d [0, 1]\n",
      "22 ['2-d']\n",
      "try0 ['2d analysis'] 23 2-d [0, 1]\n",
      "23 ['2-d']\n",
      "try0 ['2d cuo nanoleaves'] 24 2-d [0, 1]\n",
      "24 ['2-d']\n",
      "try0 ['2d mathematical model'] 25 2-d [0, 1]\n",
      "25 ['2-d']\n",
      "try0 ['2d transient thermal analysis'] 26 2-d [0, 1]\n",
      "26 ['2-d']\n",
      "27 []\n",
      "28 []\n",
      "29 []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>counts</th>\n",
       "      <th>relwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% free psa</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-d modeling</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-mhz frequency</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-year prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100% reliability</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100% renewable energy</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 min and 24 h ahead power prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500-v photovoltaic</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1d dymola</td>\n",
       "      <td>1</td>\n",
       "      <td>[1-d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1d5p model</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 deg.c target</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 to 4 level converter</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 winding coupled inductor</td>\n",
       "      <td>1</td>\n",
       "      <td>[coupled-inductor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2-d steady-state</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2-dimensional lookup table</td>\n",
       "      <td>2</td>\n",
       "      <td>[look-up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2-dof-pi-fopdn</td>\n",
       "      <td>1</td>\n",
       "      <td>[2-dof-pi-fopdn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2-stage forecasting</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.5d and 3d approach</td>\n",
       "      <td>1</td>\n",
       "      <td>[3-d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20-sim</td>\n",
       "      <td>1</td>\n",
       "      <td>[20-sim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-w/1-t co2 society vision</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   keyword  counts            relwords\n",
       "0                               % free psa       1                  []\n",
       "1                             1-d modeling       1                  []\n",
       "2                          1-mhz frequency       1                  []\n",
       "3                       10-year prediction       1                  []\n",
       "4                         100% reliability       1                  []\n",
       "5                    100% renewable energy       1                  []\n",
       "6   15 min and 24 h ahead power prediction       1                  []\n",
       "7                      1500-v photovoltaic       1     [photo-voltaic]\n",
       "8                                1d dymola       1               [1-d]\n",
       "9                               1d5p model       1                  []\n",
       "10                          2 deg.c target       1                  []\n",
       "11                  2 to 4 level converter       1                  []\n",
       "12              2 winding coupled inductor       1  [coupled-inductor]\n",
       "13                        2-d steady-state       1                  []\n",
       "14              2-dimensional lookup table       2           [look-up]\n",
       "15                          2-dof-pi-fopdn       1    [2-dof-pi-fopdn]\n",
       "16                     2-stage forecasting       1                  []\n",
       "17                    2.5d and 3d approach       1               [3-d]\n",
       "18                                  20-sim       1            [20-sim]\n",
       "19           2000-w/1-t co2 society vision       1                  []"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_value = pd.read_csv(\"keywords_value.csv\")\n",
    "df_keywords_value[\"relwords\"] = [[] for i in range(len(df_keywords_value))]\n",
    "\n",
    "for i in range(30):\n",
    "    words0 = df_keywords_value[\"keyword\"].iloc[i]\n",
    "    words1 = words0.split(\" \")\n",
    "    words2 = words0.split(\"-\")\n",
    "#     df_keywords_value.loc[i, \"relwords\"] = []\n",
    "    \n",
    "    for kws in keywords_dash:\n",
    "        kws_ = kws.replace(\"-\", \"\")\n",
    "        if kws_ in words1:\n",
    "            df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "            print(\"try0\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "\n",
    "        kws_ = kws.split('-')\n",
    "        try:\n",
    "            tmp = [words1.index(kw_) for kw_ in kws_]\n",
    "            if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "#                 print(\"try1\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                tmp = [words2.index(kw_) for kw_ in kws_]\n",
    "                if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                    df_keywords_value[\"relwords\"].iloc[i].append(kws)\n",
    "#                     print(\"try2\", [df_keywords_value[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    print(i, df_keywords_value[\"relwords\"].iloc[i])\n",
    "\n",
    "df_keywords_value.head(20)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>counts</th>\n",
       "      <th>relwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% free psa</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-d modeling</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-mhz frequency</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-year prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100% reliability</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100% renewable energy</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 min and 24 h ahead power prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500-v photovoltaic</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1d dymola</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1d5p model</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 deg.c target</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 to 4 level converter</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 winding coupled inductor</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2-d steady-state</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2-dimensional lookup table</td>\n",
       "      <td>2</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2-dof-pi-fopdn</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2-stage forecasting</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.5d and 3d approach</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20-sim</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-w/1-t co2 society vision</td>\n",
       "      <td>1</td>\n",
       "      <td>[photo-voltaic, 1-d, coupled-inductor, look-up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   keyword  counts  \\\n",
       "0                               % free psa       1   \n",
       "1                             1-d modeling       1   \n",
       "2                          1-mhz frequency       1   \n",
       "3                       10-year prediction       1   \n",
       "4                         100% reliability       1   \n",
       "5                    100% renewable energy       1   \n",
       "6   15 min and 24 h ahead power prediction       1   \n",
       "7                      1500-v photovoltaic       1   \n",
       "8                                1d dymola       1   \n",
       "9                               1d5p model       1   \n",
       "10                          2 deg.c target       1   \n",
       "11                  2 to 4 level converter       1   \n",
       "12              2 winding coupled inductor       1   \n",
       "13                        2-d steady-state       1   \n",
       "14              2-dimensional lookup table       2   \n",
       "15                          2-dof-pi-fopdn       1   \n",
       "16                     2-stage forecasting       1   \n",
       "17                    2.5d and 3d approach       1   \n",
       "18                                  20-sim       1   \n",
       "19           2000-w/1-t co2 society vision       1   \n",
       "\n",
       "                                             relwords  \n",
       "0   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "1   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "2   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "3   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "4   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "5   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "6   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "7   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "8   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "9   [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "10  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "11  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "12  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "13  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "14  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "15  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "16  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "17  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "18  [photo-voltaic, 1-d, coupled-inductor, look-up...  \n",
       "19  [photo-voltaic, 1-d, coupled-inductor, look-up...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_value.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try0 ['36-cell pv module'] 6 p-v [1, 1]\n",
      "try1 ['36-cell pv module'] 6 pv-module [1, 2]\n",
      "try0 ['3d'] 7 3-d [1, 2]\n",
      "try0 ['3d building model'] 8 3-d [1, 2]\n",
      "try0 ['3d city model'] 9 3-d [1, 2]\n",
      "try0 ['3d density model'] 10 3-d [1, 2]\n",
      "try0 ['3d experiment'] 11 3-d [1, 2]\n",
      "try0 ['3d finite element'] 12 3-d [1, 2]\n",
      "try1 ['3d finite element'] 12 finite-element [1, 2]\n",
      "try0 ['3d finite-volume modeling'] 13 3-d [1, 2]\n",
      "try0 ['3d gi'] 14 3-d [1, 2]\n",
      "try0 ['3d model'] 15 3-d [1, 2]\n",
      "try0 ['3d numerical model'] 16 3-d [1, 2]\n",
      "try0 ['3d radiative transfer'] 17 3-d [1, 2]\n",
      "try0 ['3d solar cell modeling'] 18 3-d [1, 2]\n",
      "try0 ['3d solar city'] 19 3-d [1, 2]\n",
      "try0 ['3d solar radiation model'] 20 3-d [1, 2]\n",
      "try0 ['3d urban model'] 21 3-d [1, 2]\n",
      "try2 ['3d-tlm'] 22 3d-tlm [0, 1]\n",
      "try2 ['3l-anpc'] 23 3l-anpc [0, 1]\n",
      "try2 ['4-terminal'] 24 4-terminal [0, 1]\n",
      "try1 ['5-level single phase converter'] 27 single-phase [1, 2]\n"
     ]
    }
   ],
   "source": [
    "df_keywords_value = pd.read_csv(\"keywords_value.csv\")\n",
    "\n",
    "df_tmp = df_keywords_value.iloc[30:60].reset_index(drop=True)\n",
    "df_tmp[\"relwords\"] = np.nan\n",
    "\n",
    "for i in range(30):\n",
    "    words0 = df_tmp[\"keyword\"].iloc[i]\n",
    "    words1 = words0.split(\" \")\n",
    "    words2 = words0.split(\"-\")\n",
    "    \n",
    "    for kws in keywords_dash:\n",
    "        kws_ = kws.replace(\"-\", \"\")\n",
    "        if kws_ in words1:\n",
    "            print(\"try0\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "\n",
    "        kws_ = kws.split('-')\n",
    "        try:\n",
    "            tmp = [words1.index(kw_) for kw_ in kws_]\n",
    "            if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                print(\"try1\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                tmp = [words2.index(kw_) for kw_ in kws_]\n",
    "                if tmp == sorted(tmp) and (len(np.unique(tmp)) == len(tmp)):\n",
    "                    print(\"try2\", [df_tmp[\"keyword\"].iloc[i]], i, kws, tmp)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_value_single = []\n",
    "p = re.compile(\"[a-zA-Z]\")\n",
    "\n",
    "abbkeys_ = list(keywords_abb.keys())\n",
    "abbkeys = [key.lower() for key in abbkeys]\n",
    "pluralkeys = list(keywords_plural.keys())\n",
    "\n",
    "for keyword_value in keywords_value:\n",
    "    kws = keyword_value.replace(',', \"\").split(' ')\n",
    "    for kw in kws:\n",
    "        if p.match(kw) and (kw not in abbkeys) and (kw not in keywords_dash):\n",
    "            keywords_value_single.append(kw)\n",
    "\n",
    "keywords_value_single = np.unique(keywords_value_single, return_counts=True)\n",
    "\n",
    "df_keywords_value_single = pd.DataFrame({\"keyword\": keywords_value_single[0],\n",
    "                                         \"counts\": keywords_value_single[1],\n",
    "                                         \"relwords\": [keywords_plural[kw] if kw in pluralkeys else kw for kw in keywords_value_single[0]]\n",
    "                                        })\n",
    "df_keywords_value_single[df_keywords_value_single[\"counts\"]>5].to_csv(\"keywords_relwords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* manual operation on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_noun_dict = {}\n",
    "keywords_noun_ = list(keywords_abb.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
