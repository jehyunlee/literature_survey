{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code by Sihyun You (2021.12.28.)\n",
    "* edit by Jehyun Lee (2021.12.30.)\n",
    "* revised for mrnIF by Jehyun Lee (2022.01.08.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, json\n",
    "from docx import Document\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scopus API Keys\n",
    "from my_apikeys import APIKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscriber=True\n"
     ]
    }
   ],
   "source": [
    "# subscriber (Institute: True. Home: False)\n",
    "try:\n",
    "    s_sample = ScopusSearch(f\"DOI (10.1038/s41598-021-83315-9)\").results[0]\n",
    "    subscriber=True\n",
    "except:\n",
    "    subscriber=False\n",
    "\n",
    "print(f\"subscriber={subscriber}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_date_publication(_str):\n",
    "    _str = _str.replace(\",\", \"\")\n",
    "    token_date = _str.split(' ')\n",
    "    if len(token_date) == 1: # year only\n",
    "        year = _str\n",
    "        s = _str\n",
    "    elif (re.match('[0-9]', token_date[0])):\n",
    "        day, month, year = token_date[0], token_date[1][:3].upper(), token_date[2]\n",
    "        s = ' '.join([month, day, year])\n",
    "    elif (re.match('[A-Za-z]', token_date[0]) and re.match('[0-9]', token_date[1]) and int(token_date[1])<32):    \n",
    "        month, day, year = token_date[0][:3].upper(), token_date[1], token_date[2]\n",
    "        s = ' '.join([month, day, year])\n",
    "    else:\n",
    "        month, year = token_date[0][:3].upper(), token_date[1]\n",
    "        s = ' '.join([month, year])\n",
    "        \n",
    "    return (int(year), s)\n",
    "\n",
    "def get_pub_index(_pub_name, _df):\n",
    "    list_title = _df['TITLE'].map(regularize)\n",
    "    pub_index = np.where(regularize(_pub_name) == list_title)[0]\n",
    "    if len(pub_index) > 0:\n",
    "        return pub_index\n",
    "    return np.array([])\n",
    "\n",
    "def get_pub_index_eissn(_pub_eissn, _df):\n",
    "    list_eissn = _df['EISSN'].str.replace(\"-\",\"\").values\n",
    "    pub_index = np.where(_pub_eissn == list_eissn)[0]\n",
    "    if len(pub_index) > 0:\n",
    "        return pub_index\n",
    "    return np.array([])\n",
    "\n",
    "def regularize(_str):\n",
    "    return re.sub('[^A-Za-z0-9]+', '', re.sub('&', 'and', _str)).lower()       \n",
    "\n",
    "def regularize_space(_str):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', re.sub('&', 'and', _str)).lower()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "dfs_JCR_SCIE = {}\n",
    "YEAR_START, YEAR_REMARK, YEAR_THIS = 2016, 2020, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016년도 시트를 로딩중입니다.\n",
      "2017년도 시트를 로딩중입니다.\n",
      "2018년도 시트를 로딩중입니다.\n",
      "2019년도 시트를 로딩중입니다.\n",
      "2020년도 시트를 로딩중입니다.\n"
     ]
    }
   ],
   "source": [
    "for y in range(YEAR_START, YEAR_THIS):\n",
    "    print(f\"{y}년도 시트를 로딩중입니다.\")\n",
    "    dfs_JCR_SCIE.update({str(y):pd.read_excel(\"./data/JCR_SCIE_(2016-2020)_merged.xlsx\", sheet_name=f\"JCR {y}\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EISSN 인가\n",
    "for k in dfs_JCR_SCIE.keys():\n",
    "    col_capitals = np.array([c.upper() for c in dfs_JCR_SCIE[k].columns])\n",
    "    if \"EISSN\" in col_capitals:\n",
    "        idx_eissn = np.where(\"EISSN\" == col_capitals)[0][0]\n",
    "        dfs_JCR_SCIE[k] = dfs_JCR_SCIE[k].rename(columns={dfs_JCR_SCIE[k].columns[idx_eissn]:\"EISSN\"})\n",
    "\n",
    "EISSN_2019 = dfs_JCR_SCIE[\"2019\"][[\"Title20\", \"ISO_ABBREV\", \"TITLE\", \"ISSN\", \"EISSN\"]]\n",
    "EISSN_2020 = dfs_JCR_SCIE[\"2020\"][[\"Title20\", \"ISO_ABBREV\", \"TITLE\", \"ISSN\", \"EISSN\"]]\n",
    "EISSN = pd.concat([EISSN_2019, EISSN_2020], axis=0).drop_duplicates(\"ISSN\")\n",
    "\n",
    "for k in dfs_JCR_SCIE.keys():\n",
    "    col_capitals = np.array([c.upper() for c in dfs_JCR_SCIE[k].columns])\n",
    "    if \"EISSN\" not in col_capitals:\n",
    "        dfs_JCR_SCIE[k] = dfs_JCR_SCIE[k].merge(EISSN, how=\"left\", on=[\"Title20\", \"ISO_ABBREV\", \"TITLE\", \"ISSN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2016', '2017', '2018', '2019', '2020'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_JCR_SCIE.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전체순번</th>\n",
       "      <th>수험번호내 순번</th>\n",
       "      <th>수험번호</th>\n",
       "      <th>이름</th>\n",
       "      <th>영문명</th>\n",
       "      <th>논문제목</th>\n",
       "      <th>게재일자</th>\n",
       "      <th>지원자 입력 DOI</th>\n",
       "      <th>수정 DOI</th>\n",
       "      <th>SCIE구분</th>\n",
       "      <th>역할</th>\n",
       "      <th>게재지명</th>\n",
       "      <th>출판사</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>논문구분\\n(SCIE)</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>#citation</th>\n",
       "      <th>Publication Year journal impact factor</th>\n",
       "      <th>2020\\njournal\\nimpact\\nfactor</th>\n",
       "      <th>2020 journal impact factor percentile</th>\n",
       "      <th>1st Author</th>\n",
       "      <th>1ST AUTHOR\\n(Y/N)</th>\n",
       "      <th>Reprint Author</th>\n",
       "      <th>REPRINT AUTHOR\\n(Y/N)</th>\n",
       "      <th>Source\\n(Journal)</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1409</td>\n",
       "      <td>2</td>\n",
       "      <td>0088-000276</td>\n",
       "      <td>김재형</td>\n",
       "      <td>Kim, Jae Hyung</td>\n",
       "      <td>A General Strategy to Atomically Dispersed Pre...</td>\n",
       "      <td>2020.01.30</td>\n",
       "      <td>/10.1021/acsnano.9b08494</td>\n",
       "      <td>10.1021/acsnano.9b08494</td>\n",
       "      <td>국외SCIE</td>\n",
       "      <td>주저자</td>\n",
       "      <td>ACS Nano 2020, 14, 1990-2001.</td>\n",
       "      <td>ACS</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>683</td>\n",
       "      <td>3</td>\n",
       "      <td>0088-000129</td>\n",
       "      <td>유정원</td>\n",
       "      <td>Yoo, Jeongwon</td>\n",
       "      <td>Investigation of intrinsic toroidal rotation s...</td>\n",
       "      <td>2017.07.12</td>\n",
       "      <td>/10.1063/1.4991397</td>\n",
       "      <td>10.1063/1.4991397</td>\n",
       "      <td>국외SCIE</td>\n",
       "      <td>주저자</td>\n",
       "      <td>PHYSICS OF PLASMAS 24, 072510 (2017)</td>\n",
       "      <td>AIP Publishing</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>684</td>\n",
       "      <td>4</td>\n",
       "      <td>0088-000129</td>\n",
       "      <td>유정원</td>\n",
       "      <td>Yoo, Jeongwon</td>\n",
       "      <td>Experimental evidence of intrinsic ohmic rotat...</td>\n",
       "      <td>2018.04.25</td>\n",
       "      <td>/10.1063/1.5026905</td>\n",
       "      <td>10.1063/1.5026905</td>\n",
       "      <td>국외SCIE</td>\n",
       "      <td>제2저자</td>\n",
       "      <td>Phys. Plasmas 25, 044502 (2018);</td>\n",
       "      <td>AIP Publishing</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   전체순번  수험번호내 순번         수험번호   이름             영문명  \\\n",
       "0  1409         2  0088-000276  김재형  Kim, Jae Hyung   \n",
       "1   683         3  0088-000129  유정원   Yoo, Jeongwon   \n",
       "2   684         4  0088-000129  유정원   Yoo, Jeongwon   \n",
       "\n",
       "                                                논문제목        게재일자  \\\n",
       "0  A General Strategy to Atomically Dispersed Pre...  2020.01.30   \n",
       "1  Investigation of intrinsic toroidal rotation s...  2017.07.12   \n",
       "2  Experimental evidence of intrinsic ohmic rotat...  2018.04.25   \n",
       "\n",
       "                 지원자 입력 DOI                   수정 DOI  SCIE구분    역할  \\\n",
       "0  /10.1021/acsnano.9b08494  10.1021/acsnano.9b08494  국외SCIE   주저자   \n",
       "1        /10.1063/1.4991397        10.1063/1.4991397  국외SCIE   주저자   \n",
       "2        /10.1063/1.5026905        10.1063/1.5026905  국외SCIE  제2저자   \n",
       "\n",
       "                                   게재지명             출판사 ISSN  논문구분\\n(SCIE)  \\\n",
       "0         ACS Nano 2020, 14, 1990-2001.             ACS    -           NaN   \n",
       "1  PHYSICS OF PLASMAS 24, 072510 (2017)  AIP Publishing    -           NaN   \n",
       "2      Phys. Plasmas 25, 044502 (2018);  AIP Publishing    -           NaN   \n",
       "\n",
       "   Publication Date  #citation  Publication Year journal impact factor  \\\n",
       "0               NaN        NaN                                     NaN   \n",
       "1               NaN        NaN                                     NaN   \n",
       "2               NaN        NaN                                     NaN   \n",
       "\n",
       "   2020\\njournal\\nimpact\\nfactor  2020 journal impact factor percentile  \\\n",
       "0                            NaN                                    NaN   \n",
       "1                            NaN                                    NaN   \n",
       "2                            NaN                                    NaN   \n",
       "\n",
       "   1st Author  1ST AUTHOR\\n(Y/N)  Reprint Author  REPRINT AUTHOR\\n(Y/N)  \\\n",
       "0         NaN                NaN             NaN                    NaN   \n",
       "1         NaN                NaN             NaN                    NaN   \n",
       "2         NaN                NaN             NaN                    NaN   \n",
       "\n",
       "   Source\\n(Journal)  volume  issue  Notes  \n",
       "0                NaN     NaN    NaN    NaN  \n",
       "1                NaN     NaN    NaN    NaN  \n",
       "2                NaN     NaN    NaN    NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants = pd.read_excel(\"./data/HR_input.xlsx\", header=1, dtype={\"UT\":str})\n",
    "\n",
    "# display example\n",
    "df_applicants.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_title = df_applicants[\"논문제목\"].values\n",
    "list_name_kr = df_applicants[\"이름\"].values\n",
    "list_name_en = df_applicants[\"영문명\"].values\n",
    "list_doi = df_applicants[\"수정 DOI\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528 1528\n"
     ]
    }
   ],
   "source": [
    "print(len(list_doi), len(list_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['전체순번', '수험번호내 순번', '수험번호', '이름', '영문명', '논문제목', '게재일자', '지원자 입력 DOI',\n",
       "       '수정 DOI', 'SCIE구분', '역할', '게재지명', '출판사', 'ISSN', '논문구분\\n(SCIE)',\n",
       "       'Publication Date', '#citation',\n",
       "       'Publication Year journal impact factor',\n",
       "       '2020\\njournal\\nimpact\\nfactor',\n",
       "       '2020 journal impact factor percentile', '1st Author',\n",
       "       '1ST AUTHOR\\n(Y/N)', 'Reprint Author', 'REPRINT AUTHOR\\n(Y/N)',\n",
       "       'Source\\n(Journal)', 'volume', 'issue', 'Notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- No.57 is invalid.\n",
      "- No.92 is not accessible in Scopus.\n",
      "# working on 100th article....\n",
      "# working on 200th article....\n",
      "- No.210 is invalid.\n",
      "- No.227 is invalid.\n",
      "# working on 300th article....\n",
      "- No.367 is invalid.\n",
      "# working on 400th article....\n",
      "- No.475 is invalid.\n",
      "# working on 500th article....\n",
      "- No.533 is invalid.\n",
      "# working on 600th article....\n",
      "- No.682 is invalid.\n",
      "# working on 700th article....\n",
      "- No.717 is invalid.\n",
      "- No.788 is invalid.\n",
      "- No.789 is invalid.\n",
      "# working on 800th article....\n",
      "- No.876 is invalid.\n",
      "# working on 900th article....\n",
      "- No.904 is invalid.\n",
      "- No.926 is invalid.\n",
      "- No.954 is not accessible in Scopus.\n",
      "# working on 1000th article....\n",
      "- No.1023 is not accessible in Scopus.\n",
      "- No.1045 is invalid.\n",
      "- No.1081 is invalid.\n",
      "- No.1082 is not accessible in Scopus.\n",
      "- No.1085 is not accessible in Scopus.\n",
      "- No.1088 is invalid.\n",
      "- No.1090 is invalid.\n",
      "- No.1099 is invalid.\n",
      "# working on 1100th article....\n",
      "- No.1100 is invalid.\n",
      "- No.1148 is invalid.\n",
      "# working on 1200th article....\n",
      "- No.1214 is invalid.\n",
      "- No.1219 is not accessible in Scopus.\n",
      "- No.1220 is invalid.\n",
      "- No.1244 is invalid.\n",
      "- No.1245 is invalid.\n",
      "- No.1246 is invalid.\n",
      "- No.1247 is invalid.\n",
      "- No.1248 is invalid.\n",
      "- No.1257 is invalid.\n",
      "- No.1267 is invalid.\n",
      "- No.1268 is invalid.\n",
      "- No.1269 is invalid.\n",
      "# working on 1300th article....\n",
      "- No.1330 is not accessible in Scopus.\n",
      "- No.1351 is invalid.\n",
      "- No.1352 is invalid.\n",
      "- No.1357 is invalid.\n",
      "- No.1361 is invalid.\n",
      "- No.1362 is invalid.\n",
      "- No.1363 is invalid.\n",
      "- No.1364 is invalid.\n",
      "- No.1366 is invalid.\n",
      "- No.1367 is invalid.\n",
      "- No.1368 is invalid.\n",
      "- No.1370 is invalid.\n",
      "- No.1371 is invalid.\n",
      "- No.1372 is invalid.\n",
      "- No.1373 is invalid.\n",
      "- No.1374 is invalid.\n",
      "- No.1375 is invalid.\n",
      "- No.1379 is invalid.\n",
      "- No.1380 is invalid.\n",
      "- No.1381 is invalid.\n",
      "- No.1382 is invalid.\n",
      "- No.1383 is invalid.\n",
      "- No.1386 is not accessible in Scopus.\n",
      "- No.1388 is invalid.\n",
      "- No.1391 is not accessible in Scopus.\n",
      "- No.1392 is not accessible in Scopus.\n",
      "- No.1393 is invalid.\n",
      "- No.1394 is not accessible in Scopus.\n",
      "- No.1395 is not accessible in Scopus.\n",
      "- No.1396 is invalid.\n",
      "# working on 1400th article....\n",
      "- No.1434 is invalid.\n",
      "- No.1435 is invalid.\n",
      "- No.1436 is invalid.\n",
      "- No.1466 is not accessible in Scopus.\n",
      "# working on 1500th article....\n",
      "- No.1519 is invalid.\n",
      "- No.1520 is invalid.\n",
      "- No.1521 is invalid.\n",
      "- No.1523 is invalid.\n",
      "1241\n",
      "CPU times: user 29min 16s, sys: 12 s, total: 29min 28s\n",
      "Wall time: 1h 45min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xmls = []\n",
    "\n",
    "for i, (doi, title) in enumerate(zip(list_doi, list_title)):\n",
    "    \n",
    "    # iteration\n",
    "    if i%100 == 0 and i > 0:\n",
    "        print(f\"# working on {i}th article....\")\n",
    "        \n",
    "    # notes\n",
    "    notes = []\n",
    "    \n",
    "    # article\n",
    "    s = ScopusSearch(f\"DOI ({doi})\", download=True, subscriber=subscriber).results\n",
    "    if s == None:\n",
    "        try:\n",
    "            s = ScopusSearch(f\"TITLE ({title})\", download=True, subscriber=subscriber).results\n",
    "            if s != None:\n",
    "                doi = s[0].doi\n",
    "                df_applicants[\"Notes\"][i] = f\"DOI 오류: {doi}\"\n",
    "            else:\n",
    "                print(f\"- No.{i} is invalid.\")\n",
    "                notes.append(\"doi 및 title 확인 필요\")\n",
    "                df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "                continue\n",
    "        except:\n",
    "            print(f\"- No.{i} is not accessible in Scopus.\")\n",
    "            notes.append(\"Scopus에서 접근 불가. 확인 필요\")\n",
    "            df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "            continue\n",
    "            \n",
    "        \n",
    "    info_scopus = s[0]\n",
    "\n",
    "    index_remark = get_pub_index(info_scopus.publicationName, dfs_JCR_SCIE[str(YEAR_REMARK)])\n",
    "    if len(index_remark) == 0:\n",
    "        index_remark = get_pub_index_eissn(info_scopus.eIssn, dfs_JCR_SCIE[str(YEAR_REMARK)])\n",
    "\n",
    "    scie_yn = 'N'\n",
    "    if len(index_remark) > 0:\n",
    "        scie_yn = 'Y'\n",
    "    else:\n",
    "        scie_yn = 'N'\n",
    "        notes.append(\"JCR 목록에 없음\")\n",
    "        df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "        continue\n",
    "    \n",
    "    df_applicants[\"논문구분\\n(SCIE)\"][i] = scie_yn\n",
    "    \n",
    "    year, date = regularize_date_publication(info_scopus.coverDisplayDate)\n",
    "    df_applicants[\"Publication Date\"][i] = date\n",
    "    df_applicants[\"#citation\"][i] = str(info_scopus.citedby_count)\n",
    "    \n",
    "    if year < YEAR_START:\n",
    "        notes.append(f\"{YEAR_START-1} 이전 논문\")\n",
    "        df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "        continue\n",
    "    \n",
    "    elif year < YEAR_THIS:\n",
    "        list_n = get_pub_index(info_scopus.publicationName, dfs_JCR_SCIE[str(year)])\n",
    "        if len(list_n) > 0:\n",
    "            index_n = list_n[0]\n",
    "        else:\n",
    "            list_n = get_pub_index_eissn(info_scopus.eIssn, dfs_JCR_SCIE[str(year)])\n",
    "            if len(list_n) > 0:\n",
    "                index_n = list_n[0]\n",
    "            else:\n",
    "                notes.append(f\"IF를 찾지 못함\")\n",
    "                df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "                continue\n",
    "        jif_n = str(dfs_JCR_SCIE[str(year)][\"IMPACT_FACTOR\"][index_n])\n",
    "    else:\n",
    "        jif_n = f\"{YEAR_THIS}년 출판으로 IF미발급\"\n",
    "        \n",
    "    df_applicants[\"Publication Year journal impact factor\"][i] = jif_n\n",
    "    df_applicants[\"2020\\njournal\\nimpact\\nfactor\"][i] = str(dfs_JCR_SCIE[str(YEAR_REMARK)][\"IMPACT_FACTOR\"][index_remark[0]])\n",
    "    \n",
    "    ifp = dfs_JCR_SCIE[str(YEAR_REMARK)].loc[index_remark, \"mrnIF\"]\n",
    "    try: \n",
    "        df_applicants[\"2020 journal impact factor percentile\"][i] = str(ifp.values[0])\n",
    "    except:\n",
    "        df_applicants[\"2020 journal impact factor percentile\"][i] = \"mrnIF 없음\"\n",
    "    \n",
    "    ### Author data\n",
    "    authors_raw = np.array([regularize(n) for n in info_scopus.author_names.split(\";\")])\n",
    "    \n",
    "    list_name_eni = list_name_en[i]\n",
    "    if \",\" not in list_name_eni: # 이름 성 \n",
    "        list_name_eni_ = deepcopy(list_name_eni)\n",
    "        list_name_eni_ = list_name_eni_.split(\" \")\n",
    "        list_name_eni = \", \".join(list_name_eni_[1:] + list_name_eni_[:1])\n",
    "        \n",
    "    try:\n",
    "        idx_author = np.where(regularize(list_name_eni) == authors_raw)[0][0]\n",
    "    except IndexError: # swap family and last name\n",
    "        try:\n",
    "            idx_author = np.where(regularize(\"\".join(list_name_eni.split(\",\")[::-1])) == authors_raw)[0][0]\n",
    "        except IndexError : # possibly disturbed by middle names\n",
    "            idx_author=None\n",
    "            author_name_words = regularize_space(list_name_eni).split(\" \")\n",
    "            name_words = [regularize_space(name).rstrip(\" \").split(\" \") for name in info_scopus.author_names.split(\";\")]\n",
    "            for j, name_word in enumerate(name_words):\n",
    "                name_check = list(set(author_name_words) - set(name_word))\n",
    "                if len(name_check) == 0:\n",
    "                    idx_author = j\n",
    "                    notes.append(\"지원자 성명 확인 필요\")\n",
    "                    \n",
    "    if idx_author == None:\n",
    "        # 이니셜로만 되어있는건 아닌지 확인\n",
    "        familyname = list_name_eni.split(\", \")[0].lower()\n",
    "        firstname = list_name_eni.split(\", \")[1].lower()\n",
    "        name_TF = [True if ((n[0] == familyname and len(set(n[1:])-set(firstname))==0) or \n",
    "                            (n[-1]==familyname and len(set(n[:-1])-set(firstname))==0)) \n",
    "                   else False \n",
    "                   for n in name_words]\n",
    "        if len(np.where(np.array(name_TF)==True)[0]) > 0:\n",
    "            idx_author = np.where(np.array(name_TF)==True)[0][0]\n",
    "            notes.append(\"논문 저자 이름이 약어로 표현됨. 확인 필요.\")\n",
    "        else:\n",
    "            notes.append(\"지원자가 저자 명단에 없음\")\n",
    "            \n",
    "        \n",
    "    # first author    \n",
    "    if idx_author == 0:\n",
    "        first_author = list_name_eni\n",
    "        first_author_yn = \"Y\"\n",
    "    else:\n",
    "        first_author = info_scopus.author_names.split(\";\")[0]\n",
    "        first_author_yn = \"N\"    \n",
    "    \n",
    "    df_applicants[\"1st Author\"][i] = first_author\n",
    "    df_applicants[\"1ST AUTHOR\\n(Y/N)\"][i] = first_author_yn    \n",
    "    df_applicants[\"1st Author\"][i] = first_author\n",
    "    \n",
    "        \n",
    "    ### Publication\n",
    "    df_applicants[\"Source\\n(Journal)\"][i] = info_scopus.publicationName.upper()\n",
    "    df_applicants[\"volume\"][i] = info_scopus.volume\n",
    "    \n",
    "    if info_scopus.issueIdentifier != None:\n",
    "        issue = info_scopus.issueIdentifier\n",
    "    else:\n",
    "        issue = ''\n",
    "    df_applicants[\"issue\"][i] = issue\n",
    "    \n",
    "    # PDF download\n",
    "    accept = \"application/pdf\"\n",
    "    HEADERS = {\n",
    "        'X-ELS-APIKEY': APIKeys[-1],\n",
    "        'Accept': accept\n",
    "    }\n",
    "    url = f'http://api.elsevier.com/content/article/doi:{doi}?view=FULL'\n",
    "    try:\n",
    "        r = requests.get(url, stream=True, headers=HEADERS)\n",
    "        if r.status_code == 200: # download supported in Scopus\n",
    "            if accept == \"application/pdf\":\n",
    "                for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                    with open(f\"./pdf/paper_{i+1}.pdf\", \"wb\") as f:\n",
    "                        f.write(chunk)\n",
    "            elif accept == \"text/xml\":\n",
    "                xml = BeautifulSoup(r.content, \"html5lib\")\n",
    "                xmls.append(xml)\n",
    "                with open(f\"./xml/xml_{i+1}.xml\", \"w\") as f:\n",
    "                    f.write(xml.prettify())\n",
    "            \n",
    "        # XML data mining\n",
    "        url = f\"https://doi.org/{doi}\"\n",
    "        r = requests.get(url)\n",
    "        xml = BeautifulSoup(r.content, \"html5lib\")\n",
    "        xmls.append(xml)            \n",
    "        with open(f\"./xml/xml_{i+1}.xml\", \"w\") as f:\n",
    "            f.write(xml.prettify())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # write in every step\n",
    "    df_applicants[\"Notes\"][i] = \"\\n\".join(notes)\n",
    "    df_applicants.to_excel(\"applicants_fill.xlsx\", index=False)\n",
    "    \n",
    "print(len(xmls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
